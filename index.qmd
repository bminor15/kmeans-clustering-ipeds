---
title: "Capstone: K-Means Clustering on Retail Data"
subtitle: "This is a Report Template Quarto"
author: "Lavanya Guntupalli, Benjamin Minor, Charan Gullipalli, Arun Pandian"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
nocite: "@*"
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!

Nice report!
:::

## Introduction

In retail, not all customers are the same. Some shop often and spend a
lot, while others buy less or shop only occasionally. Treating all
customers the same can lead to missed opportunities. K-Means clustering
helps retailers by grouping customers with similar behaviors, such as
spending levels or shopping frequency. These groups can then be targeted
with the right offers, discounts, and services. Beyond customers,
K-Means can also be used in inventory management, dividing products into
fast-moving, stable, or slow-moving categories to reduce waste and
improve stock planning.

For this project we are working with a retail dataset that holds
transactional records with details on purchases and spending patterns.
Our plan is to clean and prepare the data, choose features that capture
customer and product behavior, and then apply K-Means clustering to see
how the groups form. From there we will evaluate the clusters and
describe them in clear terms, showing how the results can guide
decisions for marketing, promotions, and inventory.

The introduction should:

-   Develop a storyline that captures attention and maintains interest.

-   Your audience is your peers

-   Clearly state the problem or question you're addressing.

<!-- -->

-   Introduce why it is relevant needs.

-   Provide an overview of your approach.

Example of writing including citing references:

*This is an introduction to ..... regression, which is a non-parametric
estimator that estimates the conditional expectation of two variables
which is random. The goal of a kernel regression is to discover the
non-linear relationship between two random variables. To discover the
non-linear relationship, kernel estimator or kernel smoothing is the
main method to estimate the curve for non-parametric statistics. In
kernel estimator, weight function is known as kernel function
[@efr2008]. Cite this paper [@bro2014principal]. The GEE [@wang2014].
The PCA [@daffertshofer2004pca]*. Topology can be used in machine
learning [@adams2021topology]

For Symbolic Regression [@wang2019symbolic] *This is my work and I want
to add more work...*

Cite new paper [@su2012linear]

## Literature

- Customer segmentation through clustering techniques has become essential for retailers to understand consumer behavior and improve marketing and inventory decisions. K-Means clustering is still a popular technique among these due to its ease of use, interpretability, and effectiveness when working with big datasets. The following studies show how K-Means has been successfully used in a variety of retail settings, including department shops, supermarkets, and online platforms.


- K-Means was utilized in another study on a department store example to create user profiles using membership and transaction data. The authors identified ideal clusters that reflected important shopper kinds, such as high-value regulars and sporadic low spenders, using the elbow approach and the Calinskiâ€“Harabasz index. Although the study highlighted the importance of clustering for targeted marketing and loyalty programs, it lacked behavioral or demographic diversity, which prevented a more thorough understanding of consumer motives.

-  A study that used a weighted K-Means version with RFM (Recency, Frequency, Monetary) analysis aimed to improve segmentation accuracy in the online retail industry. The weighted version outperformed the regular K-Means (around 0.30) in terms of silhouette scores using a sizable UK retail dataset (about 0.40). More useful client clusters for targeting and retention were produced by this method. However, it overlooked other behavioral elements like browsing or engagement patterns because it just used RFM data.

- Several clustering techniques, including K-Means, Gaussian Mixture Models (GMM), DBSCAN, BIRCH, and Agglomerative clustering, were investigated using RFM-based features in a comparative analysis on UK retail data. The results indicated that K-Means remained the most practical due to its simplicity and quick computation, but GMM performed the best (silhouette score ~0.80). The study came to the conclusion that segmentation quality is greatly impacted by algorithm choice, and that results might be further improved with richer datasets.

- All things considered, the examined literature suggests K-Means clustering is a dependable and flexible method for retail customer segmentation. It enables data-driven marketing, inventory, and customer relationship management initiatives by assisting organizations in meaningfully grouping their customers. Although the majority of studies still only use transactional data, those that incorporate weighted features or RFM analysis show increased accuracy. In order to obtain more thorough and useful segmentation findings, future studies should investigate hybrid models and incorporate behavioral and demographic data.



## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{python}
import pandas as pd
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
