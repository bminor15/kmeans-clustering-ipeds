---
title: "Capstone: K-Means Clustering on Retail Data"
author: "Lavanya Guntupalli, Benjamin Minor, Charan Gullipalli, Arun Pandian"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
nocite: "@*"
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)



## Introduction

In retail, not all customers are the same. Some shop often and spend a
lot, while others buy less or shop only occasionally. Treating all
customers the same can lead to missed opportunities. K-Means clustering
helps retailers by grouping customers with similar behaviors, such as
spending levels or shopping frequency. These groups can then be targeted
with the right offers, discounts, and services. Beyond customers,
K-Means can also be used in inventory management, dividing products into
fast-moving, stable, or slow-moving categories to reduce waste and
improve stock planning.

For this project we are working with a retail dataset that holds
transactional records with details on purchases and spending patterns.
Our plan is to clean and prepare the data, choose features that capture
customer and product behavior, and then apply K-Means clustering to see
how the groups form. From there we will evaluate the clusters and
describe them in clear terms, showing how the results can guide
decisions for marketing, promotions, and inventory.


## Literature

<details>
<summary><strong>Source Summaries (click to expand)</strong></summary>

<div class="markdown" style="margin-top:1rem;">

### Benjamin Minor — Literature Review

**Customer Analytics for Online Retailers Using Weighted K-Means and RFM Analysis**  
[PDF Link](https://pdfs.semanticscholar.org/2094/679b670242e4177670b839fd7736fc454afa.pdf)  
The paper looks at how online shops can do a better job grouping their customers. The authors say this is important because regular K Means can give weak groups, which makes it harder for businesses to target the right people. They used a UK online retail dataset, built recency, frequency, and monetary features, and then ran both standard K Means and a weighted version to see which worked better. The weighted method came out stronger, with a silhouette score of about 0.40 compared to 0.30 for the normal version. One drawback is that using just RFM features leaves out other behaviors, so the results do not show the full picture of customer activity.  

**An Exploration of Clustering Algorithms for Customer Segmentation in the UK Retail Market**  
[PDF Link](https://arxiv.org/pdf/2402.04103)  
The paper compares different clustering methods to see which one makes the best customer groups. This matters for retail because the choice of algorithm changes how useful the clusters are for marketing and planning. The authors took the same UK online retail dataset, used RFM features, and tested K Means, Gaussian Mixture Models, DBSCAN, BIRCH, and agglomerative clustering. They compared the results with silhouette scores. Gaussian Mixture Models did the best with a score close to 0.80, while K Means and the other methods were lower. A limitation is that the dataset only had transaction data, so there were no demographics or other factors that could make the groups more detailed.  

**Application Of K-Means Clustering For Customer Segmentation In Grocery Stores In Kenya**  
[Article Link](https://ijstm.inarah.co.id/index.php/ijstm/article/view/1024)  
This article looked at how grocery stores in Kenya used K-Means clustering to group their customers. They worked with both transaction and demographic data, cleaned it up, and then tested different numbers of clusters with the elbow method. The clusters showed clear groups of shoppers with different buying habits. By knowing these groups, the stores could adjust marketing and stock decisions. The main point is that even in smaller or resource-limited businesses, clustering can help them better understand and serve customers.  

**Applying K-Means Clustering for User Profiling in Retail: A Department Store Case Study**  
[PDF Link](https://www.atlantis-press.com/article/125992628.pdf)  
This case study focused on a department store that used customer and membership data to apply K-Means clustering. They tested different cluster sizes with the elbow method and Calinski-Harabasz index, and ended up with four customer profiles. These profiles were based on things like spending level, age, and shopping frequency. From the results, the store could build more targeted marketing and loyalty programs. The takeaway is that K-Means can break down a broad customer base into smaller groups, making it easier for retailers to plan strategies.  

**Customer Segmentation Using RFM and K-Means Clustering to Support CRM in Retail Industry**  
[ResearchGate Link](https://www.researchgate.net/publication/394047969_Customer_Segmentation_Using_RFM_and_K-Means_Clustering_to_Support_CRM_in_Retail_Industry)  
This paper looks at a small local retailer with about 2,300 transactions over three years and asks how they can split customers into groups using K Means with RFM features. It matters because smaller shops usually don’t have advanced analytics tools but still need to know who their loyal or at-risk customers are. The authors cleaned and normalized the data, applied K Means, and used the elbow method to choose four clusters. They labeled them loyal, potential loyalists, at risk, and one time buyers. The results gave the shop useful customer groups, but the limits were that the dataset was small and static and didn’t include other behaviors like browsing or reviews.  

**Product Clustering Analysis on the Marketplace Using K Means Approach (Case Study: Shopee)**  
[ResearchGate Link](https://www.researchgate.net/publication/365377295_PRODUCT_CLUSTERING_ANALYSIS_ON_THE_MARKETPLACE_USING_K-MEANS_APPROACH_CASE_STUDY_SHOPEE)  
This study used Shopee marketplace data to group products instead of customers. The goal was to see which products act alike based on attributes like price, ratings, and stock. It’s important because sellers need to know which products belong together so they can adjust pricing, promotions, and inventory. The authors scraped product data, processed it, and ran K Means with different cluster sizes, checking results with the Davies-Bouldin Index. They found that three or four clusters worked best depending on the category. The results gave decent product groupings, but there were limits: scraped data can be noisy, categories can be too broad, and seasonal changes in demand were not included.  

</div>
</details>
 

</div>
</details>

## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{python}
import pandas as pd
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
::: {#refs .hanging-indent}
:::
